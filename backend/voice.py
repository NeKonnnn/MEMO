import os
import sys
import torch
import queue
import sounddevice as sd
import re
import time
import json
from pathlib import Path
from vosk import Model, KaldiRecognizer
from backend.agent import ask_agent
from backend.memory import save_to_memory

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ librosa –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–µ–º–ø–∞ –∞—É–¥–∏–æ
try:
    import librosa
    import librosa.effects
    librosa_available = True
    print("librosa –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–µ–º–ø–∞ –∞—É–¥–∏–æ")
except ImportError:
    librosa_available = False
    print("librosa –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–µ–º–ø–∞ –∞—É–¥–∏–æ –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
SAMPLE_RATE = 16000
VOSK_MODEL_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "model_small")
SILERO_MODELS_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'silero_models')
MODELS_URLS = {
    'ru': 'https://models.silero.ai/models/tts/ru/v3_1_ru.pt',
    'en': 'https://models.silero.ai/models/tts/en/v3_en.pt'
}
MODEL_PATHS = {
    'ru': os.path.join(SILERO_MODELS_DIR, 'ru', 'model.pt'),
    'en': os.path.join(SILERO_MODELS_DIR, 'en', 'model.pt')
}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è TTS
models = {}
tts_model_loaded = False
pyttsx3_engine = None

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ TTS
try:
    import pyttsx3
    pyttsx3_available = True
except ImportError:
    pyttsx3_available = False
    print("–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: pyttsx3 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∑–∞–ø–∞—Å–Ω–æ–π TTS –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

#---------- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–µ–º–ø–∞ –∞—É–¥–∏–æ ----------#

def change_audio_speed(audio, sample_rate, speed_factor):
    """–ò–∑–º–µ–Ω—è–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã"""
    if not librosa_available:
        print("librosa –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ")
        return audio
    
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º torch tensor –≤ numpy array
        if isinstance(audio, torch.Tensor):
            audio_numpy = audio.cpu().numpy()
        else:
            audio_numpy = audio
        
        # –ò–∑–º–µ–Ω—è–µ–º —Ç–µ–º–ø –∞—É–¥–∏–æ
        audio_fast = librosa.effects.time_stretch(audio_numpy, rate=speed_factor)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ torch tensor
        if isinstance(audio, torch.Tensor):
            return torch.from_numpy(audio_fast)
        else:
            return audio_fast
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ç–µ–º–ø–∞ –∞—É–¥–∏–æ: {e}")
        return audio

#---------- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (Silero TTS) ----------#

def init_pyttsx3():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã pyttsx3"""
    global pyttsx3_engine
    if pyttsx3_available:
        try:
            pyttsx3_engine = pyttsx3.init()
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–æ–ª–æ—Å–∞
            voices = pyttsx3_engine.getProperty('voices')
            for voice in voices:
                if 'russian' in str(voice).lower() or 'ru' in str(voice).lower():
                    pyttsx3_engine.setProperty('voice', voice.id)
                    break
            return True
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ pyttsx3: {e}")
    return False

def download_model(lang):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞, –µ—Å–ª–∏ –æ–Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"""
    model_path = MODEL_PATHS[lang]
    model_url = MODELS_URLS[lang]
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    
    if not os.path.isfile(model_path):
        print(f"–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å {lang} –∏–∑ {model_url}")
        try:
            torch.hub.download_url_to_file(model_url, model_path)
            print(f"–ú–æ–¥–µ–ª—å {lang} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {lang}: {e}")
            return False
    return True

def load_model(lang):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    global models, tts_model_loaded
    
    if lang in models:
        return True
        
    model_path = MODEL_PATHS[lang]
    
    try:
        if os.path.isfile(model_path):
            model = torch.package.PackageImporter(model_path).load_pickle("tts_models", "model")
            model.to('cpu')
            models[lang] = model
            tts_model_loaded = True
            return True
        else:
            print(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ {lang} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {lang}: {e}")
        return False

def init_tts():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã TTS"""
    global tts_model_loaded
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pyttsx3 –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
    pyttsx3_initialized = init_pyttsx3()
    
    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä—É—Å—Å–∫—É—é –º–æ–¥–µ–ª—å
    if download_model('ru') and load_model('ru'):
        tts_model_loaded = True
    
    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫—É—é –º–æ–¥–µ–ª—å
    download_model('en') and load_model('en')

def split_text_into_chunks(text, max_chunk_size=1000):
    """–î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏, –¥–ª–∏–Ω–∞ –∫–∞–∂–¥–æ–π –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç max_chunk_size —Å–∏–º–≤–æ–ª–æ–≤"""
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = re.split(r'(?<=[.!?])\s+', text)
    chunks = []
    current_chunk = ""

    for sentence in sentences:
        # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏–º–∏—Ç,
        # —Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –∫ —Ç–µ–∫—É—â–µ–º—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É
        if len(current_chunk) + len(sentence) + 1 <= max_chunk_size:
            current_chunk += sentence + " "
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence + " "
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

def detect_language(text):
    """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
    cyrillic_count = sum(1 for char in text if '–∞' <= char.lower() <= '—è' or char.lower() in '—ë—ñ—ó—î“ë')
    
    # –ï—Å–ª–∏ –±–æ–ª–µ–µ 50% —Å–∏–º–≤–æ–ª–æ–≤ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ, —Å—á–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç —Ä—É—Å—Å–∫–∏–º
    if cyrillic_count / max(1, len(text)) > 0.5:
        return 'ru'
    else:
        return 'en'

def speak_text_silero(text, speaker='baya', sample_rate=48000, lang=None, speech_rate=1.0, save_to_file=None):
    """–û–∑–≤—É—á–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é Silero TTS"""
    global models
    
    if not text:
        return False
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
    if lang is None:
        lang = detect_language(text)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ª–∏ –Ω—É–∂–Ω–∞—è –º–æ–¥–µ–ª—å
    if lang not in models:
        if not load_model(lang):
            return False
    
    try:
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–µ—á–∏
        print(f"–ü—Ä–∏–º–µ–Ω—è—é —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏: {speech_rate}x")
        print(f"–ò—Å—Ö–æ–¥–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {sample_rate} Hz")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —á–∞—Å—Ç–æ—Ç—É –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è Silero
        effective_sample_rate = 48000  # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        
        print(f"–ò—Å–ø–æ–ª—å–∑—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —á–∞—Å—Ç–æ—Ç—É –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {effective_sample_rate} Hz")
        print(f"–°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ –±—É–¥–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∞ —á–µ—Ä–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–µ–º–ø–∞ –∞—É–¥–∏–æ: {speech_rate}x")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        if len(text.strip()) < 10:
            # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∑–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            text = f"–û—Ç–≤–µ—Ç: {text.replace(',', ' –∏ ').replace('.', ' —Ç–æ—á–∫–∞').replace('1', '–æ–¥–∏–Ω').replace('2', '–¥–≤–∞').replace('3', '—Ç—Ä–∏').replace('4', '—á–µ—Ç—ã—Ä–µ').replace('5', '–ø—è—Ç—å')}"
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏, –µ—Å–ª–∏ –æ–Ω –¥–ª–∏–Ω–Ω—ã–π
        chunks = split_text_into_chunks(text)
        all_audio = []
        
        for i, chunk in enumerate(chunks):
            if i > 0:
                time.sleep(0.3)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏
                
            try:
                audio = models[lang].apply_tts(
                    text=chunk, 
                    speaker=speaker,
                    sample_rate=effective_sample_rate,
                    put_accent=False,  # –£–±–∏—Ä–∞–µ–º –∞–∫—Ü–µ–Ω—Ç—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    put_yo=False       # –£–±–∏—Ä–∞–µ–º —ë –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                )
                
                # –ò–∑–º–µ–Ω—è–µ–º —Ç–µ–º–ø –∞—É–¥–∏–æ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–µ—á–∏
                if speech_rate != 1.0:
                    print(f"–ò–∑–º–µ–Ω—è—é —Ç–µ–º–ø –∞—É–¥–∏–æ —Å {speech_rate}x")
                    audio = change_audio_speed(audio, effective_sample_rate, speech_rate)
                
                if save_to_file:
                    all_audio.append(audio)
                else:
                    sd.play(audio, effective_sample_rate)
                    sd.wait()
                    
            except Exception as chunk_error:
    
                # –ü—ã—Ç–∞–µ–º—Å—è —Å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
                try:
                    simplified_chunk = chunk.replace(',', '').replace('.', '').replace('!', '').replace('?', '')
                    if simplified_chunk.strip():
                        audio = models[lang].apply_tts(
                            text=simplified_chunk, 
                            speaker='baya',  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –≥–æ–ª–æ—Å
                            sample_rate=effective_sample_rate,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ —á–∞—Å—Ç–æ—Ç—É
                            put_accent=False,
                            put_yo=False
                        )
                        
                        # –ò–∑–º–µ–Ω—è–µ–º —Ç–µ–º–ø –∞—É–¥–∏–æ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–µ—á–∏
                        if speech_rate != 1.0:
                            print(f"Fallback: –∏–∑–º–µ–Ω—è—é —Ç–µ–º–ø –∞—É–¥–∏–æ —Å {speech_rate}x")
                            audio = change_audio_speed(audio, effective_sample_rate, speech_rate)
                        
                        if save_to_file:
                            all_audio.append(audio)
                        else:
                            sd.play(audio, effective_sample_rate)
                            sd.wait()
                except Exception as fallback_error:
                    print(f"Fallback —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {fallback_error}")
                    continue
        
        if save_to_file and all_audio:
            try:
                import torch
                import scipy.io.wavfile
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ –∞—É–¥–∏–æ
                combined_audio = torch.cat(all_audio, dim=0)
                audio_numpy = combined_audio.cpu().numpy()
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∞—É–¥–∏–æ
                if audio_numpy.max() <= 1.0:
                    audio_numpy = (audio_numpy * 32767).astype('int16')
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª —Å —É—á–µ—Ç–æ–º –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–π —á–∞—Å—Ç–æ—Ç—ã –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
                scipy.io.wavfile.write(save_to_file, effective_sample_rate, audio_numpy)
                print(f"–ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {save_to_file}")
                return True
                
            except Exception as save_error:
                print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ: {save_error}")
                return False
        
        return True
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ç–µ–∑–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Silero: {e}")
        import traceback
        traceback.print_exc()
        return False

def speak_text_pyttsx3(text, speech_rate=1.0):
    """–û–∑–≤—É—á–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é pyttsx3"""
    global pyttsx3_engine
    
    if not text or not pyttsx3_engine:
        return False
    
    try:
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏
        rate = int(200 * speech_rate)
        print(f"pyttsx3: —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ {speech_rate}x (rate={rate})")
        pyttsx3_engine.setProperty('rate', rate)  # –ë–∞–∑–æ–≤–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å 200
        pyttsx3_engine.say(text)
        pyttsx3_engine.runAndWait()
        return True
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ç–µ–∑–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ pyttsx3: {e}")
        return False

def speak_text(text, speaker='baya', voice_id='ru', speech_rate=1.0, save_to_file=None):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
    print(f"üîß speak_text –≤—ã–∑–≤–∞–Ω–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: speaker={speaker}, voice_id={voice_id}, speech_rate={speech_rate}")
    
    if not text:
        return False
    
    # –ü—ã—Ç–∞–µ–º—Å—è –æ–∑–≤—É—á–∏—Ç—å —á–µ—Ä–µ–∑ Silero
    if tts_model_loaded and speak_text_silero(text, speaker, lang=voice_id, speech_rate=speech_rate, save_to_file=save_to_file):
        return True
    
    # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º pyttsx3 (—Ç–æ–ª—å–∫–æ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è, –Ω–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)
    if not save_to_file and speak_text_pyttsx3(text, speech_rate):
        return True
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ
    print("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–∑–≤—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç:", text[:50] + "..." if len(text) > 50 else text)
    return False

#---------- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ (Vosk) ----------#

def check_vosk_model():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏"""
    if not os.path.exists(VOSK_MODEL_PATH):
        print(f"–û–®–ò–ë–ö–ê: –ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {VOSK_MODEL_PATH}")
        return False
    return True

def recognize_speech():
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
    if not check_vosk_model():
        raise Exception("–ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    try:
        model = Model(VOSK_MODEL_PATH)
        q = queue.Queue()

        def callback(indata, frames, time, status):
            if status:
                print("–û—à–∏–±–∫–∞:", status, file=sys.stderr)
            q.put(bytes(indata))

        print("–°–∫–∞–∂–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å (Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞)...")
        with sd.RawInputStream(samplerate=SAMPLE_RATE, blocksize=8000, dtype='int16',
                              channels=1, callback=callback):
            rec = KaldiRecognizer(model, SAMPLE_RATE)
            while True:
                data = q.get()
                if rec.AcceptWaveform(data):
                    result = json.loads(rec.Result())
                    return result.get("text", "")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏: {e}")
        return ""

def recognize_speech_from_file(file_path):
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –∏—Å–ø–æ–ª—å–∑—É—è —Ç—É –∂–µ –ª–æ–≥–∏–∫—É —á—Ç–æ –∏ recognize_speech"""
    if not check_vosk_model():
        raise Exception("–ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    try:
        import wave
        import numpy as np
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª: {file_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(file_path):
            raise Exception(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = os.path.getsize(file_path)
        print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
        
        if file_size < 10:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ª—é–±–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
            print("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª –¥–ª—è —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∞—É–¥–∏–æ")
            return ""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        converted_file_path = None
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
            with open(file_path, 'rb') as f:
                header = f.read(12)
            
            is_wav = header.startswith(b'RIFF') and b'WAVE' in header
            is_webm = header.startswith(b'\x1a\x45\xdf\xa3')  # WebM signature
            
            if not is_wav:
                print(f"–§–∞–π–ª –Ω–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ WAV, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é...")
        
                
                try:
                    from pydub import AudioSegment
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –≤ –ª—é–±–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                    if is_webm:
                        print("–û–±–Ω–∞—Ä—É–∂–µ–Ω WebM —Ñ–æ—Ä–º–∞—Ç")
                        audio = AudioSegment.from_file(file_path, format="webm")
                    else:
                        print("–ü—ã—Ç–∞—é—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ–∂–∏–º–µ")
                        audio = AudioSegment.from_file(file_path)
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                    audio = audio.set_frame_rate(SAMPLE_RATE)  # 16kHz
                    audio = audio.set_channels(1)  # –º–æ–Ω–æ
                    audio = audio.set_sample_width(2)  # 16-bit
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ WAV
                    import tempfile
                    temp_dir = tempfile.gettempdir()
                    converted_file_path = os.path.join(temp_dir, f"converted_{os.path.basename(file_path)}.wav")
                    audio.export(converted_file_path, format="wav")
                    
            
                    file_path = converted_file_path
                    
                except ImportError:
                    print("pydub –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –Ω–µ –º–æ–≥—É –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑ WebM")
                    return ""
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º
                    pass
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ñ–æ—Ä–º–∞—Ç–∞: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º
        
        # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–∫ WAV —Ñ–∞–π–ª
        try:
            with wave.open(file_path, 'rb') as wf:
                # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∞–π–ª–∞
                channels = wf.getnchannels()
                sampwidth = wf.getsampwidth()
                framerate = wf.getframerate()
                nframes = wf.getnframes()
                
        
                
                if nframes == 0:
                    print("–ê—É–¥–∏–æ—Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö")
                    return ""
                
                # –ß–∏—Ç–∞–µ–º –≤—Å–µ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ
                frames = wf.readframes(nframes)
                
                if len(frames) == 0:
                    print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ")
                    return ""
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                if sampwidth == 1:
                    dtype = np.uint8
                elif sampwidth == 2:
                    dtype = np.int16
                elif sampwidth == 4:
                    dtype = np.int32
                else:
                    dtype = np.int16
                
                audio_array = np.frombuffer(frames, dtype=dtype)
                
                if len(audio_array) == 0:
                    print("–ü—É—Å—Ç–æ–π –∞—É–¥–∏–æ –º–∞—Å—Å–∏–≤")
                    return ""
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–æ–Ω–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if channels == 2:
                    print("–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é —Å—Ç–µ—Ä–µ–æ –≤ –º–æ–Ω–æ")
                    if len(audio_array) % 2 != 0:
                        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ —á–µ—Ç–Ω–æ–≥–æ —á–∏—Å–ª–∞ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ reshape
                        audio_array = audio_array[:-1]
                    audio_array = audio_array.reshape(-1, 2)
                    audio_array = np.mean(audio_array, axis=1).astype(dtype)
                    channels = 1
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ 16-–±–∏—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if sampwidth != 2:
                    print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é —Ä–∞–∑—Ä—è–¥–Ω–æ—Å—Ç—å —Å {sampwidth*8} –Ω–∞ 16 –±–∏—Ç")
                    if sampwidth == 1:
                        # 8-–±–∏—Ç –≤ 16-–±–∏—Ç (unsigned to signed)
                        audio_array = ((audio_array.astype(np.float32) - 128) * 256).astype(np.int16)
                    elif sampwidth == 4:
                        # 32-–±–∏—Ç –≤ 16-–±–∏—Ç
                        audio_array = (audio_array // 65536).astype(np.int16)
                    sampwidth = 2
                
                # –†–µ—Å—ç–º–ø–ª–∏–Ω–≥ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–ø—Ä–æ—Å—Ç–æ–π decimation/interpolation)
                if framerate != SAMPLE_RATE:
                    print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é —á–∞—Å—Ç–æ—Ç—É —Å {framerate} –Ω–∞ {SAMPLE_RATE}")
                    if len(audio_array) > 1:
                        # –ü—Ä–æ—Å—Ç–æ–π —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥
                        ratio = SAMPLE_RATE / framerate
                        new_length = max(1, int(len(audio_array) * ratio))
                        indices = np.linspace(0, len(audio_array) - 1, new_length)
                        audio_array = np.interp(indices, np.arange(len(audio_array)), audio_array.astype(np.float32)).astype(np.int16)
                        framerate = SAMPLE_RATE
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –±–∞–π—Ç—ã
                frames = audio_array.tobytes()
                
        
        
        except (wave.Error, EOFError, Exception) as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è WAV —Ñ–∞–π–ª–∞: {e}")
            print("–ü–æ–ø—ã—Ç–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–∫ raw –∞—É–¥–∏–æ...")
            
            # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ raw –∞—É–¥–∏–æ
            try:
                with open(file_path, 'rb') as f:
                    raw_data = f.read()
                    
                if len(raw_data) < 4:
                    print("–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–µ")
                    return ""
                
                # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ 16-–±–∏—Ç –∞—É–¥–∏–æ
                # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                if raw_data.startswith(b'RIFF'):
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–æ–±—ã—á–Ω–æ 44 –±–∞–π—Ç–∞)
                    header_size = 44
                    if len(raw_data) > header_size:
                        raw_data = raw_data[header_size:]
                    else:
                        print("–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫")
                        return ""
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 16-–±–∏—Ç–Ω—ã–µ —Å—ç–º–ø–ª—ã
                if len(raw_data) % 2 != 0:
                    raw_data = raw_data[:-1]  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π –±–∞–π—Ç
                
                frames = raw_data
                framerate = SAMPLE_RATE
                sampwidth = 2
                channels = 1
                
        
                
            except Exception as e2:
                print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è raw –∞—É–¥–∏–æ: {e2}")
                return ""
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        model = Model(VOSK_MODEL_PATH)
        rec = KaldiRecognizer(model, framerate)
        
        print("–ù–∞—á–∏–Ω–∞—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ –ø–æ—Ä—Ü–∏—è–º–∏
        results = []
        chunk_size = framerate * sampwidth * channels // 10  # 0.1 —Å–µ–∫—É–Ω–¥—ã
        
        for i in range(0, len(frames), chunk_size):
            chunk = frames[i:i + chunk_size]
            if len(chunk) == 0:
                break
                
            if rec.AcceptWaveform(chunk):
                result = json.loads(rec.Result())
                text = result.get("text", "")
                if text.strip():
                    results.append(text.strip())
                    print(f"–ß–∞—Å—Ç–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {text}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        final_result = json.loads(rec.FinalResult())
        final_text = final_result.get("text", "")
        if final_text.strip():
            results.append(final_text.strip())
            print(f"–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {final_text}")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        full_text = " ".join(results).strip()

        
        return full_text
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏ –∏–∑ —Ñ–∞–π–ª–∞: {e}")
        import traceback
        traceback.print_exc()
        return ""  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –≤–º–µ—Å—Ç–æ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
    finally:
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω
        if converted_file_path and os.path.exists(converted_file_path):
            try:
                os.remove(converted_file_path)
                print(f"–£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {converted_file_path}")
            except Exception as e:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {e}")
        pass

def run_voice():
    """–ó–∞–ø—É—Å–∫ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –≤ –∫–æ–Ω—Å–æ–ª–∏"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
    if not check_vosk_model():
        print("–ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        raise Exception("–ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É TTS
    init_tts()
    
    try:
        print("–ì–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º –∑–∞–ø—É—â–µ–Ω. –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞.")
        while True:
            try:
                phrase = recognize_speech()
                if not phrase:
                    continue
                print("–í—ã:", phrase)
                save_to_memory("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å", phrase)

                response = ask_agent(phrase)
                print("–ê–≥–µ–Ω—Ç:", response)
                speak_text(response)
                save_to_memory("–ê–≥–µ–Ω—Ç", response)
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
                print("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞...")

    except KeyboardInterrupt:
        print("\n–ì–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º –∑–∞–≤–µ—Ä—à—ë–Ω.")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º TTS –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è
init_tts() 